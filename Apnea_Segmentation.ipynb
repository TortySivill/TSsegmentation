{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed75c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import stumpy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316be5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotations = []\n",
    "ecgs = []\n",
    "\n",
    "for file_index in range(1,10):\n",
    "    #file_name = files.split(\".\")[0]\n",
    "    ecg = wfdb.rdsamp('apnea/apnea/a0'+str(file_index))\n",
    "    ecgs.append(ecg[0].reshape(len(ecg[0])))\n",
    "    annotation = wfdb.rdann('apnea/apnea/a0'+str(file_index), extension=\"apn\")\n",
    "    annotations.append(annotation.symbol)\n",
    "for file_index in range(10,21):\n",
    "    #file_name = files.split(\".\")[0]\n",
    "    ecg = wfdb.rdsamp('apnea/apnea/a'+str(file_index))\n",
    "    ecgs.append(ecg[0].reshape(len(ecg[0])))\n",
    "    annotation = wfdb.rdann('apnea/apnea/a'+str(file_index), extension=\"apn\")\n",
    "    annotations.append(annotation.symbol)\n",
    "\n",
    "for file_index in range(1,6):\n",
    "    #file_name = files.split(\".\")[0]\n",
    "    ecg = wfdb.rdsamp('apnea/apnea/b0'+str(file_index))\n",
    "    ecgs.append(ecg[0].reshape(len(ecg[0])))\n",
    "    annotation = wfdb.rdann('apnea/apnea/b0'+str(file_index), extension=\"apn\")\n",
    "    annotations.append(annotation.symbol)\n",
    "\n",
    "for file_index in range(1,10):\n",
    "    #file_name = files.split(\".\")[0]\n",
    "    ecg = wfdb.rdsamp('apnea/apnea/c0'+str(file_index))\n",
    "    ecgs.append(ecg[0].reshape(len(ecg[0])))\n",
    "    annotation = wfdb.rdann('apnea/apnea/c0'+str(file_index), extension=\"apn\")\n",
    "    annotations.append(annotation.symbol)\n",
    "for file_index in range(10,11):\n",
    "    #file_name = files.split(\".\")[0]\n",
    "    ecg = wfdb.rdsamp('apnea/apnea/c'+str(file_index))\n",
    "    ecgs.append(ecg[0])\n",
    "    annotation = wfdb.rdann('apnea/apnea/c'+str(file_index), extension=\"apn\")\n",
    "    annotations.append(annotation.symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eed2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## simplify ecg signal by getting one sample per second (reduced from 100 samples/second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49fa8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ecgs = []\n",
    "for ecg in ecgs:\n",
    "    simple_ecgs.append(ecg.reshape(-1, 100).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ab849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proposed Algorithm \n",
    "def extract_stationary_indexes(t, window_size, sliding_window, break_points, round_index):\n",
    "    matrix_profile = stumpy.stump(np.asarray(t,dtype=float), m=window_size)\n",
    "    df_matrix_profile = pd.DataFrame(matrix_profile)\n",
    "\n",
    "    \n",
    "    df_matrix_profile['left_index']= matrix_profile[:,1]\n",
    "    proposed_change_points = []\n",
    "\n",
    "    for x in range(0,len(df_matrix_profile.index)-1):\n",
    "            if df_matrix_profile['left_index'].iloc[x+1] != df_matrix_profile['left_index'].iloc[x] + 1:\n",
    "                proposed_change_points.append(x)\n",
    "\n",
    "    \n",
    "    variance_changes = []\n",
    "    final_indexes = []\n",
    "    for x in proposed_change_points:\n",
    "        if x < sliding_window:\n",
    "            continue\n",
    "        elif x > len(t) - sliding_window:\n",
    "            continue\n",
    "        else:\n",
    "            final_indexes.append(x)\n",
    "            window_mean = np.mean([t[y] for y in range(x-sliding_window, x)])/np.std([t[y] for y in range(x-sliding_window, x)])\n",
    "            next_window_mean = np.mean([t[y] for y in range(x,x+sliding_window)])/np.std([t[y] for y in range(x,x+sliding_window)])\n",
    "        \n",
    "        if x < sliding_window:\n",
    "            continue\n",
    "        elif x > len(t) - sliding_window:\n",
    "            continue\n",
    "        else:\n",
    "            window_std = np.std([t[y] for y in range(x-sliding_window, x)])\n",
    "            next_window_std = np.std([t[y] for y in range(x,x+sliding_window)])\n",
    "        \n",
    "            mean_change = np.abs(window_mean - next_window_mean)\n",
    "            std_change = np.abs(window_std - next_window_std)\n",
    "            variance_changes.append(mean_change * std_change)\n",
    "            #variance_changes.append(mean_change)\n",
    "\n",
    "    df_entropy_changes = pd.DataFrame()\n",
    "    #df_entropy_changes['indexes'] = proposed_change_points\n",
    "    df_entropy_changes['indexes'] = final_indexes\n",
    "    df_entropy_changes['relative_variance'] = variance_changes\n",
    "\n",
    "    df_entropy_changes = df_entropy_changes[df_entropy_changes['relative_variance'] != 0]\n",
    "    \n",
    "    df_entropy_changes['rounded_indexes'] = [round(x,round_index) for x in df_entropy_changes['indexes']]\n",
    "    df_sorted = df_entropy_changes.loc[df_entropy_changes.groupby('rounded_indexes').relative_variance.idxmax()]\n",
    "    df_entropy_sorted = df_sorted.sort_values(by='relative_variance')\n",
    "\n",
    "    selected_indexes = []\n",
    "    for x in df_entropy_sorted['indexes'].iloc[len(df_entropy_sorted['rounded_indexes'])-break_points: len(df_entropy_sorted['rounded_indexes'])]:\n",
    "        selected_indexes.append(x)\n",
    "    return selected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e172a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "ground_truth_indexes = []\n",
    "my_indexes = []\n",
    "flussy_indexes = []\n",
    "import ruptures as rpt\n",
    "ruptures_indexes = []\n",
    "\n",
    "for i in range(0,len(simple_ecgs)):\n",
    "    print(i)\n",
    "    labels = annotations[i]\n",
    "    signal = simple_ecgs[i]\n",
    "    \n",
    "    \n",
    "    number_regimes = 1\n",
    "    N_indexes = []\n",
    "\n",
    "    for label_index in range(0,len(labels)-1):\n",
    "        if labels[label_index] != labels[label_index + 1]:\n",
    "            number_regimes += 1\n",
    "            N_indexes.append((label_index+1)*60)\n",
    "    \n",
    "    ground_truth_indexes.append(N_indexes)\n",
    "    my_indexes.append(extract_stationary_indexes(signal,60,300,number_regimes-1,-3))\n",
    "    m = 60\n",
    "    mp = stumpy.stump(signal, m=m)\n",
    "    L = 60\n",
    "    cac, regime_locations = stumpy.fluss(mp[:, 1], L=L, n_regimes=number_regimes, excl_factor=5)\n",
    "    flussy_indexes.append(regime_locations)\n",
    "    print(\"here\")\n",
    "    algo = rpt.Dynp(model=\"l2\").fit(signal)\n",
    "    result = algo.predict(n_bkps=number_regimes)\n",
    "    ruptures_indexes.append(result)\n",
    "    \n",
    "    \"\"\"model = \"rbf\"  # \"l1\", \"rbf\", \"linear\", \"normal\", \"ar\"\n",
    "    algo = rpt.Window(width=60, model=model).fit(signal)\n",
    "    my_bkps = algo.predict(epsilon=1)\n",
    "    ruptures2_indexes.append(my_bkps)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruptures_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d996e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a72fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "flussy_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(simple_ecgs[0])\n",
    "for index in [4513, 25252, 3467, 4317, 13695]:\n",
    "    plt.axvline(index,color='magenta')\n",
    "for index in [12058, 11748, 11411, 12358, 10958]:\n",
    "    plt.axvline(index,color='yellow')\n",
    "for index in [780, 13620, 13860, 21120, 21240]:\n",
    "    plt.axvline(index,color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb964ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(simple_ecgs[1])\n",
    "for index in [27560,\n",
    "  22214,\n",
    "  21048,\n",
    "  7493,\n",
    "  486,\n",
    "  19514,\n",
    "  4476,\n",
    "  7811,\n",
    "  554,\n",
    "  31416,\n",
    "  16705,\n",
    "  26133,\n",
    "  10296,\n",
    "  13038,\n",
    "  15303,\n",
    "  19300,\n",
    "  15604,\n",
    "  12116,\n",
    "  30080,\n",
    "  10905,\n",
    "  1989]:\n",
    "    plt.axvline(index,color='magenta')\n",
    "for index in [1749,  8549, 10766,  8178,  8941,  6618, 10465,  3415, 11066,\n",
    "         9720,  1446,  7453,  7767,  6147,  6993, 10134,  9241,  3788,\n",
    "         5796, 11447, 11775]:\n",
    "    plt.axvline(index,color='yellow')\n",
    "for index in [1260,\n",
    "  7800,\n",
    "  10560,\n",
    "  12060,\n",
    "  12420,\n",
    "  15960,\n",
    "  16200,\n",
    "  16920,\n",
    "  17280,\n",
    "  17700,\n",
    "  17820,\n",
    "  18480,\n",
    "  18720,\n",
    "  19560,\n",
    "  19740,\n",
    "  23340,\n",
    "  23520,\n",
    "  25920,\n",
    "  26160,\n",
    "  30000,\n",
    "  30540]:\n",
    "    plt.axvline(index,color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(simple_ecgs[2][10:])\n",
    "for index in [16690,\n",
    "  28215,\n",
    "  20828,\n",
    "  25576,\n",
    "  4147,\n",
    "  18125,\n",
    "  29740,\n",
    "  6329,\n",
    "  9004,\n",
    "  26734,\n",
    "  14045,\n",
    "  14679,\n",
    "  15786,\n",
    "  30944,\n",
    "  13436,\n",
    "  29302,\n",
    "  24247,\n",
    "  11255,\n",
    "  24956,\n",
    "  11593,\n",
    "  300]:\n",
    "    plt.axvline(index,color='magenta')\n",
    "for index in [12791, 12215, 11289, 11674, 13091, 13494, 15981, 13794, 14193,\n",
    "        15283, 14932, 15628, 16416, 14493, 10965, 17658, 17266, 18008,\n",
    "        20906, 18376, 16716]:\n",
    "    plt.axvline(index,color='yellow')\n",
    "for index in [780,\n",
    "  3600,\n",
    "  6300,\n",
    "  8820,\n",
    "  11160,\n",
    "  13740,\n",
    "  14400,\n",
    "  15480,\n",
    "  17400,\n",
    "  18180,\n",
    "  20820,\n",
    "  21180,\n",
    "  23100,\n",
    "  24360,\n",
    "  24660,\n",
    "  25020,\n",
    "  25620,\n",
    "  26580,\n",
    "  28200,\n",
    "  29520,\n",
    "  30420]:\n",
    "    plt.axvline(index,color='green')\n",
    "    \n",
    "plt.savefig('apneasegmentation.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52979cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(my_indexes)):\n",
    "    my_index = my_indexes[i].sort()\n",
    "    flussy_index = flussy_indexes[i].sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(ground_truth_indexes)):\n",
    "    ground_truth_indexes[i].sort()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth_indexes[0])\n",
    "print(my_indexes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_samples_hits = []\n",
    "my_total_true_cp = 0\n",
    "my_total_predicted_cp = 0\n",
    "wrong_score = 0\n",
    "for sample in range(0,len(my_indexes)):\n",
    "    sample_hits = 0\n",
    "    tolerance = len(simple_ecgs[sample])/10\n",
    "    ground_truth = ground_truth_indexes[sample]\n",
    "    if len(ground_truth) == len(my_indexes[sample]):\n",
    "        my_total_true_cp += len(ground_truth)\n",
    "        my_total_predicted_cp += len(my_indexes[sample])\n",
    "        for i in range(0,len(ground_truth)):\n",
    "            if my_indexes[sample][i] in np.arange(ground_truth[i]-tolerance,ground_truth[i]+tolerance):\n",
    "                sample_hits = sample_hits + 1\n",
    "        my_samples_hits.append(sample_hits)\n",
    "    else:\n",
    "        wrong_score += 1\n",
    "print(wrong_score)        \n",
    "my_samples_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "flussy_true_cp = 0\n",
    "flussy_predicted_cp = 0\n",
    "flussy_samples_hits = []\n",
    "wrong_score = 0\n",
    "for sample in range(0,len(flussy_indexes)):\n",
    "    sample_hits = 0\n",
    "    tolerance = len(simple_ecgs[sample])/10\n",
    "    ground_truth = ground_truth_indexes[sample]\n",
    "    if len(ground_truth) == len(flussy_indexes[sample]):\n",
    "        flussy_true_cp += len(ground_truth)\n",
    "        flussy_predicted_cp += len(flussy_indexes[sample])\n",
    "        for i in range(0,len(ground_truth)):\n",
    "            if flussy_indexes[sample][i] in np.arange(ground_truth[i]-tolerance,ground_truth[i]+tolerance):\n",
    "                sample_hits = sample_hits + 1\n",
    "        flussy_samples_hits.append(sample_hits)\n",
    "    else:\n",
    "        wrong_score += 1\n",
    "print(wrong_score)        \n",
    "flussy_samples_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f95f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_samples_precision = sum(my_samples_hits)/my_total_predicted_cp\n",
    "\n",
    "my_samples_recall = sum(my_samples_hits)/my_total_true_cp\n",
    "\n",
    "\n",
    "my_samples_fscore = 2 * my_samples_precision * my_samples_recall/(my_samples_precision + my_samples_recall)\n",
    "\n",
    "my_samples_fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ce045",
   "metadata": {},
   "outputs": [],
   "source": [
    "flussy_samples_precision = sum(flussy_samples_hits)/flussy_predicted_cp\n",
    "\n",
    "flussy_samples_recall = sum(flussy_samples_hits)/flussy_true_cp\n",
    "\n",
    "\n",
    "flussy_samples_fscore = 2 * flussy_samples_precision * flussy_samples_recall/(flussy_samples_precision + flussy_samples_recall)\n",
    "\n",
    "flussy_samples_fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50085dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_samples_hausdorff = []\n",
    "wrong_score = 0\n",
    "for sample in range(0,len(my_indexes)):\n",
    "    max_distance = 0\n",
    "    ground_truth = ground_truth_indexes[sample]\n",
    "    if len(ground_truth) == len(my_indexes[sample]):\n",
    "        for i in range(0,len(ground_truth)):\n",
    "            if np.abs(my_indexes[sample][i]-ground_truth[i]) > max_distance:\n",
    "                max_distance = np.abs(my_indexes[sample][i]-ground_truth[i])\n",
    "        my_samples_hausdorff.append(max_distance/len(simple_ecgs[sample]))\n",
    "    else:\n",
    "        wrong_score += 1\n",
    "print(wrong_score)        \n",
    "np.mean(my_samples_hausdorff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d972ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "flussy_samples_hausdorff = []\n",
    "wrong_score = 0\n",
    "for sample in range(0,len(flussy_indexes)):\n",
    "    max_distance = 0\n",
    "    ground_truth = ground_truth_indexes[sample]\n",
    "    if len(ground_truth) == len(flussy_indexes[sample]):\n",
    "        for i in range(0,len(ground_truth)):\n",
    "            if np.abs(flussy_indexes[sample][i]-ground_truth[i]) > max_distance:\n",
    "                max_distance = np.abs(flussy_indexes[sample][i]-ground_truth[i])\n",
    "        flussy_samples_hausdorff.append(max_distance/len(simple_ecgs[sample]))\n",
    "    else:\n",
    "        wrong_score += 1\n",
    "print(wrong_score)        \n",
    "np.mean(flussy_samples_hausdorff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fac58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
